<!DOCTYPE html>
<html lang="">
    <!-- title -->




<!-- keywords -->




<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no" >
    <meta name="author" content="jax">
    <meta name="renderer" content="webkit">
    <meta name="copyright" content="jax">
    
    <meta name="keywords" content="hexo,lipsky,lipsky-blog">
    
    <meta name="description" content="Help myself">
    <meta name="description" content="爬取京东《刻意练习》图书评论并生成图词前言：  本文主要为爬虫入门篇，通过简单的 requests 模块，爬取京东销售的图书《刻意练习》的评论，并生成云图词，体验爬虫的小乐趣。  实现的目的《刻意练习》这本书是一本非常棒的书，作者通过长时间的观察和亲身实践，研究和讲述学习的过程，以及从新手到大师 master 的必经之路，和刻意练习之方法。 如果非常喜欢这本书，想看一下买这本书的人对于这本书的评价">
<meta property="og:type" content="article">
<meta property="og:title" content="Spider for a Book &quot;Secrets from the New Science of Expertise&quot; comments on JD.com">
<meta property="og:url" content="https://github.com/liysky/liysky.github.io.git/2019/08/06/Spider-for-a-Book-Secrets-from-the-New-Science-of-Expertise-comments-on-JD-com/index.html">
<meta property="og:site_name" content="GuoXin Li&#39;s Blog">
<meta property="og:description" content="爬取京东《刻意练习》图书评论并生成图词前言：  本文主要为爬虫入门篇，通过简单的 requests 模块，爬取京东销售的图书《刻意练习》的评论，并生成云图词，体验爬虫的小乐趣。  实现的目的《刻意练习》这本书是一本非常棒的书，作者通过长时间的观察和亲身实践，研究和讲述学习的过程，以及从新手到大师 master 的必经之路，和刻意练习之方法。 如果非常喜欢这本书，想看一下买这本书的人对于这本书的评价">
<meta property="og:image" content="http://ww4.sinaimg.cn/large/006tNc79ly1g5p993jskkj319w0u0dkw.jpg">
<meta property="og:image" content="http://ww2.sinaimg.cn/large/006tNc79ly1g5p98urf7uj30c005g74c.jpg">
<meta property="og:image" content="http://ww2.sinaimg.cn/large/006tNc79ly1g5p9995ax4j319w0u0n3u.jpg">
<meta property="og:image" content="http://ww4.sinaimg.cn/large/006tNc79ly1g5p995jo04j31bx0u0jvk.jpg">
<meta property="og:image" content="http://ww3.sinaimg.cn/large/006tNc79ly1g5p98zr984j30ul0u0tbt.jpg">
<meta property="og:image" content="http://ww2.sinaimg.cn/large/006tNc79ly1g5p99ahotzj31bx0u07bu.jpg">
<meta property="og:image" content="http://ww4.sinaimg.cn/large/006tNc79ly1g5p98z7gerj31bx0u07ap.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/006tNc79ly1g5p98txpahj325g0sigvc.jpg">
<meta property="og:image" content="http://ww2.sinaimg.cn/large/006tNc79ly1g5p98shx7oj319w0u0dkw.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/006tNc79ly1g5p992mwjqj31ow0u0aev.jpg">
<meta property="og:image" content="http://ww3.sinaimg.cn/large/006tNc79ly1g5p993y9esj30u00za0vl.jpg">
<meta property="og:image" content="http://ww4.sinaimg.cn/large/006tNc79ly1g5p9933zhgj31bx0u07b9.jpg">
<meta property="og:image" content="http://ww4.sinaimg.cn/large/006tNc79ly1g5p991ztw8j30u00zaapz.jpg">
<meta property="og:image" content="http://ww3.sinaimg.cn/large/006tNc79ly1g5p997r6x0j31bx0u047m.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/006tNc79ly1g5p996ggu4j31d50u0tdg.jpg">
<meta property="og:image" content="http://ww3.sinaimg.cn/large/006tNc79ly1g5p990di8fj31c00u0gub.jpg">
<meta property="og:image" content="http://ww2.sinaimg.cn/large/006tNc79ly1g5koj6jwo6j31ow0u0grq.jpg">
<meta property="og:image" content="http://ww2.sinaimg.cn/large/006tNc79ly1g5p994gjiwj31fu0qcq8v.jpg">
<meta property="og:image" content="http://ww3.sinaimg.cn/large/006tNc79ly1g5p9977n1tj30l60bijs3.jpg">
<meta property="og:image" content="http://ww3.sinaimg.cn/large/006tNc79ly1g5p998rmigj315g0u042r.jpg">
<meta property="og:image" content="http://ww4.sinaimg.cn/large/006tNc79ly1g5p999mhymj30x90u0n4e.jpg">
<meta property="article:published_time" content="2019-08-05T16:12:41.000Z">
<meta property="article:modified_time" content="2020-05-05T15:36:20.000Z">
<meta property="article:author" content="jax">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://ww4.sinaimg.cn/large/006tNc79ly1g5p993jskkj319w0u0dkw.jpg">
    <meta http-equiv="Cache-control" content="no-cache">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
    
    <link rel="alternate" href="/atom.xml" title="GuoXin Li&#39;s Blog" type="application/atom+xml">
    
    <title>Spider for a Book &#34;Secrets from the New Science of Expertise&#34; comments on JD.com · GuoXin Li&#39;s Blog</title>
    <style type="text/css">
    @font-face {
        font-family: 'Oswald-Regular';
        src: url("/font/Oswald-Regular.ttf");
    }

    body {
        margin: 0;
    }

    header,
    footer,
    .back-top,
    .sidebar,
    .container,
    .site-intro-meta,
    .toc-wrapper {
        display: none;
    }

    .site-intro {
        position: relative;
        z-index: 3;
        width: 100%;
        /* height: 50vh; */
        overflow: hidden;
    }

    .site-intro-placeholder {
        position: absolute;
        z-index: -2;
        top: 0;
        left: 0;
        width: calc(100% + 300px);
        height: 100%;
        background: repeating-linear-gradient(-45deg, #444 0, #444 80px, #333 80px, #333 160px);
        background-position: center center;
        transform: translate3d(-226px, 0, 0);
        animation: gradient-move 2.5s ease-out 0s infinite;
    }

    @keyframes gradient-move {
        0% {
            transform: translate3d(-226px, 0, 0);
        }
        100% {
            transform: translate3d(0, 0, 0);
        }
    }

</style>

    <link rel="preload" href= "/css/style.css?v=20180824" as="style" onload="this.onload=null;this.rel='stylesheet'" />
    <link rel="stylesheet" href= "/css/mobile.css?v=20180824" media="(max-width: 980px)">
    
    <link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'" />
    
    <!-- /*! loadCSS. [c]2017 Filament Group, Inc. MIT License */
/* This file is meant as a standalone workflow for
- testing support for link[rel=preload]
- enabling async CSS loading in browsers that do not support rel=preload
- applying rel preload css once loaded, whether supported or not.
*/ -->
<script>
(function( w ){
	"use strict";
	// rel=preload support test
	if( !w.loadCSS ){
		w.loadCSS = function(){};
	}
	// define on the loadCSS obj
	var rp = loadCSS.relpreload = {};
	// rel=preload feature support test
	// runs once and returns a function for compat purposes
	rp.support = (function(){
		var ret;
		try {
			ret = w.document.createElement( "link" ).relList.supports( "preload" );
		} catch (e) {
			ret = false;
		}
		return function(){
			return ret;
		};
	})();

	// if preload isn't supported, get an asynchronous load by using a non-matching media attribute
	// then change that media back to its intended value on load
	rp.bindMediaToggle = function( link ){
		// remember existing media attr for ultimate state, or default to 'all'
		var finalMedia = link.media || "all";

		function enableStylesheet(){
			link.media = finalMedia;
		}

		// bind load handlers to enable media
		if( link.addEventListener ){
			link.addEventListener( "load", enableStylesheet );
		} else if( link.attachEvent ){
			link.attachEvent( "onload", enableStylesheet );
		}

		// Set rel and non-applicable media type to start an async request
		// note: timeout allows this to happen async to let rendering continue in IE
		setTimeout(function(){
			link.rel = "stylesheet";
			link.media = "only x";
		});
		// also enable media after 3 seconds,
		// which will catch very old browsers (android 2.x, old firefox) that don't support onload on link
		setTimeout( enableStylesheet, 3000 );
	};

	// loop through link elements in DOM
	rp.poly = function(){
		// double check this to prevent external calls from running
		if( rp.support() ){
			return;
		}
		var links = w.document.getElementsByTagName( "link" );
		for( var i = 0; i < links.length; i++ ){
			var link = links[ i ];
			// qualify links to those with rel=preload and as=style attrs
			if( link.rel === "preload" && link.getAttribute( "as" ) === "style" && !link.getAttribute( "data-loadcss" ) ){
				// prevent rerunning on link
				link.setAttribute( "data-loadcss", true );
				// bind listeners to toggle media back
				rp.bindMediaToggle( link );
			}
		}
	};

	// if unsupported, run the polyfill
	if( !rp.support() ){
		// run once at least
		rp.poly();

		// rerun poly on an interval until onload
		var run = w.setInterval( rp.poly, 500 );
		if( w.addEventListener ){
			w.addEventListener( "load", function(){
				rp.poly();
				w.clearInterval( run );
			} );
		} else if( w.attachEvent ){
			w.attachEvent( "onload", function(){
				rp.poly();
				w.clearInterval( run );
			} );
		}
	}


	// commonjs
	if( typeof exports !== "undefined" ){
		exports.loadCSS = loadCSS;
	}
	else {
		w.loadCSS = loadCSS;
	}
}( typeof global !== "undefined" ? global : this ) );
</script>

    <link rel="icon" href= "/assets/favicon.ico" />
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.min.js" as="script" />
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js" as="script" />
    <link rel="preload" href="/scripts/main.js" as="script" />
    <link rel="preload" as="font" href="/font/Oswald-Regular.ttf" crossorigin>
    <link rel="preload" as="font" href="https://at.alicdn.com/t/font_327081_1dta1rlogw17zaor.woff" crossorigin>
    
    <!-- fancybox -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" defer></script>
    <!-- 百度统计  -->
    
    <!-- 谷歌统计  -->
    
<meta name="generator" content="Hexo 4.2.0"></head>

    
        <body class="post-body">
    
    
<header class="header">

    <div class="read-progress"></div>
    <div class="header-sidebar-menu">&#xe775;</div>
    <!-- post页的toggle banner  -->
    
    <div class="banner">
            <div class="blog-title">
                <a href="/" >GuoXin Li&#39;s Blog</a>
            </div>
            <div class="post-title">
                <a href="#" class="post-name">Spider for a Book "Secrets from the New Science of Expertise" comments on JD.com</a>
            </div>
    </div>
    
    <a class="home-link" href=/>GuoXin Li's Blog</a>
</header>
    <div class="wrapper">
        <div class="site-intro" style="







height:50vh;
">
    
    <!-- 主页  -->
    
    
    <!-- 404页  -->
            
    <div class="site-intro-placeholder"></div>
    <div class="site-intro-img" style="background-image: url(https://source.unsplash.com/random/1600x500)"></div>
    <div class="site-intro-meta">
        <!-- 标题  -->
        <h1 class="intro-title">
            <!-- 主页  -->
            
            Spider for a Book "Secrets from the New Science of Expertise" comments on JD....
            <!-- 404 -->
            
        </h1>
        <!-- 副标题 -->
        <p class="intro-subtitle">
            <!-- 主页副标题  -->
            
            
            <!-- 404 -->
            
        </p>
        <!-- 文章页meta -->
        
            <div class="post-intros">
                <!-- 文章页标签  -->
                
                
                    <div class="post-intro-read">
                        <span>字数统计: <span class="post-count word-count">4.2k</span>阅读时长: <span class="post-count reading-time">16 min</span></span>
                    </div>
                
                <div class="post-intro-meta">
                    <span class="post-intro-calander iconfont-archer">&#xe676;</span>
                    <span class="post-intro-time">2019/08/06</span>
                    
                    <span id="busuanzi_container_page_pv" class="busuanzi-pv">
                        <span class="iconfont-archer">&#xe602;</span>
                        <span id="busuanzi_value_page_pv"></span>
                    </span>
                    
                    <span class="shareWrapper">
                        <span class="iconfont-archer shareIcon">&#xe71d;</span>
                        <span class="shareText">Share</span>
                        <ul class="shareList">
                            <li class="iconfont-archer share-qr" data-type="qr">&#xe75b;
                                <div class="share-qrcode"></div>
                            </li>
                            <li class="iconfont-archer" data-type="weibo">&#xe619;</li>
                            <li class="iconfont-archer" data-type="qzone">&#xe62e;</li>
                            <li class="iconfont-archer" data-type="twitter">&#xe634;</li>
                            <li class="iconfont-archer" data-type="facebook">&#xe67a;</li>
                        </ul>
                    </span>
                </div>
            </div>
        
    </div>
</div>
        <script>
 
  // get user agent
  var browser = {
    versions: function () {
      var u = window.navigator.userAgent;
      return {
        userAgent: u,
        trident: u.indexOf('Trident') > -1, //IE内核
        presto: u.indexOf('Presto') > -1, //opera内核
        webKit: u.indexOf('AppleWebKit') > -1, //苹果、谷歌内核
        gecko: u.indexOf('Gecko') > -1 && u.indexOf('KHTML') == -1, //火狐内核
        mobile: !!u.match(/AppleWebKit.*Mobile.*/), //是否为移动终端
        ios: !!u.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/), //ios终端
        android: u.indexOf('Android') > -1 || u.indexOf('Linux') > -1, //android终端或者uc浏览器
        iPhone: u.indexOf('iPhone') > -1 || u.indexOf('Mac') > -1, //是否为iPhone或者安卓QQ浏览器
        iPad: u.indexOf('iPad') > -1, //是否为iPad
        webApp: u.indexOf('Safari') == -1, //是否为web应用程序，没有头部与底部
        weixin: u.indexOf('MicroMessenger') == -1, //是否为微信浏览器
        uc: u.indexOf('UCBrowser') > -1 //是否为android下的UC浏览器
      };
    }()
  }
  console.log("userAgent:" + browser.versions.userAgent);

  // callback
  function fontLoaded() {
    console.log('font loaded');
    if (document.getElementsByClassName('site-intro-meta')) {
      document.getElementsByClassName('intro-title')[0].classList.add('intro-fade-in');
      document.getElementsByClassName('intro-subtitle')[0].classList.add('intro-fade-in');
      var postIntros = document.getElementsByClassName('post-intros')[0]
      if (postIntros) {
        postIntros.classList.add('post-fade-in');
      }
    }
  }

  // UC不支持跨域，所以直接显示
  function asyncCb(){
    if (browser.versions.uc) {
      console.log("UCBrowser");
      fontLoaded();
    } else {
      WebFont.load({
        custom: {
          families: ['Oswald-Regular']
        },
        loading: function () {  //所有字体开始加载
          // console.log('loading');
        },
        active: function () {  //所有字体已渲染
          fontLoaded();
        },
        inactive: function () { //字体预加载失败，无效字体或浏览器不支持加载
          console.log('inactive: timeout');
          fontLoaded();
        },
        timeout: 5000 // Set the timeout to two seconds
      });
    }
  }

  function asyncErr(){
    console.warn('script load from CDN failed, will load local script')
  }

  // load webfont-loader async, and add callback function
  function async(u, cb, err) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (cb) { o.addEventListener('load', function (e) { cb(null, e); }, false); }
    if (err) { o.addEventListener('error', function (e) { err(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }

  var asyncLoadWithFallBack = function(arr, success, reject) {
      var currReject = function(){
        reject()
        arr.shift()
        if(arr.length)
          async(arr[0], success, currReject)
        }

      async(arr[0], success, currReject)
  }

  asyncLoadWithFallBack([
    "https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.min.js", 
    "https://cdn.bootcss.com/webfont/1.6.28/webfontloader.js",
    "/lib/webfontloader.min.js"
  ], asyncCb, asyncErr)
</script>        
        <img class="loading" src="/assets/loading.svg" style="display: block; margin: 6rem auto 0 auto; width: 6rem; height: 6rem;" />
        <div class="container container-unloaded">
            <main class="main post-page">
    <article class="article-entry">
        <h1 id="爬取京东《刻意练习》图书评论并生成图词"><a href="#爬取京东《刻意练习》图书评论并生成图词" class="headerlink" title="爬取京东《刻意练习》图书评论并生成图词"></a>爬取京东《刻意练习》图书评论并生成图词</h1><p><strong>前言：</strong></p>
<blockquote>
<p>本文主要为爬虫入门篇，通过简单的 requests 模块，爬取京东销售的图书《刻意练习》的评论，并生成云图词，体验爬虫的小乐趣。</p>
</blockquote>
<h4 id="实现的目的"><a href="#实现的目的" class="headerlink" title="实现的目的"></a>实现的目的</h4><p>《刻意练习》这本书是一本非常棒的书，作者通过长时间的观察和亲身实践，研究和讲述学习的过程，以及从新手到大师 master 的必经之路，和刻意练习之方法。</p>
<p>如果非常喜欢这本书，想看一下买这本书的人对于这本书的评价是什么样的，当然可以自己去看评论区，但是只能草略的看，想全面的评论统计，那么就需要爬虫出马了。</p>
<p>通过爬虫可以快速地，大量地爬取到有关这本图书的几乎所有的评论，然后统计所有评论中的关键词，生成词图，达到我们快速了解购买这本书的读者的评价的目的。</p>
<h4 id="上手"><a href="#上手" class="headerlink" title="上手"></a>上手</h4><h5 id="首先，我们需要打开京东关于这本书的评论，这很简单，用浏览器我们可以办得到（推荐使用-Chrome-浏览器，可能会更加方便）"><a href="#首先，我们需要打开京东关于这本书的评论，这很简单，用浏览器我们可以办得到（推荐使用-Chrome-浏览器，可能会更加方便）" class="headerlink" title="首先，我们需要打开京东关于这本书的评论，这很简单，用浏览器我们可以办得到（推荐使用 Chrome 浏览器，可能会更加方便）"></a><strong>首先，我们需要打开京东关于这本书的评论，这很简单，用浏览器我们可以办得到（推荐使用 Chrome 浏览器，可能会更加方便）</strong></h5><p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g5p993jskkj319w0u0dkw.jpg" alt="Screen Shot 2019-08-02 at 00.14.33"></p>
<p>我们点击中间的商品评价，所有的评论便都在下面了。</p>
<h4 id="第一行代码"><a href="#第一行代码" class="headerlink" title="第一行代码"></a>第一行代码</h4><p>本次爬取数据，使用的是 Python 的一个库——<strong>Requests</strong>，在这里我们只需要明白它是一个特别强大的库就可以了，如果想要了解更多关于<strong>Requests</strong>的内容，我们只需要用搜索引擎搜索它，然后详细仔细的查看和研究，本文我们变用变学习<strong>Requests</strong> 的功能。</p>
<h5 id="导入-Requests-库"><a href="#导入-Requests-库" class="headerlink" title="导入 Requests 库"></a>导入 Requests 库</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br></pre></td></tr></table></figure>
<p>上面这第一行代码意思是将<strong>Requests</strong>库导入当前python文件，只有导入后才能使用（Python 有很多的库文件，我们用哪个就需要提前导入哪个）</p>
<h5 id="定义评论链接"><a href="#定义评论链接" class="headerlink" title="定义评论链接"></a>定义评论链接</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">url = <span class="string">"https://sclub.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98vv2783&amp;productId=11990777&amp;score=0&amp;sortType=5&amp;page=0&amp;pageSize=10&amp;isShadowSku=0&amp;rid=0&amp;fold=1"</span></span><br></pre></td></tr></table></figure>
<p>这段代码定义一个 url 变量，并将<strong>评论链接</strong>赋值给url这个变量，但是这个<strong>评论链接</strong>是从哪里找到的呢？有了这个疑问，这也是本次教程最重要的部分。</p>
<h4 id="找到评论链接"><a href="#找到评论链接" class="headerlink" title="找到评论链接"></a>找到评论链接</h4><p><strong>要想获得所有评论，我们要有一个概念，1. 其实评论肯定都存储在京东的服务器上，2. 当我们点击评论的时候，浏览器向服务器索要评论内容，3. 服务器会给出一个评论链接，4. 浏览器通过这个评论链接便能查看所有的评论</strong></p>
<p>好，我们可以理解为，有一条线，这条线牵引着所有的评论内容。接下来我们的目的就是找到这条线。</p>
<h4 id="打开浏览器开发模式"><a href="#打开浏览器开发模式" class="headerlink" title="打开浏览器开发模式"></a>打开浏览器开发模式</h4><p>按 F12（或者 <strong>fn键+F12</strong>），再或者在评论区的当前页面 <strong>右击</strong> 然后点击 <strong>检查（inspect）</strong> 选项，开发者模式就被我们调出来了。具体如下图：</p>
<p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g5p98urf7uj30c005g74c.jpg" alt="Screen Shot 2019-08-02 at 00.22.48"></p>
<p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g5p9995ax4j319w0u0n3u.jpg" alt="image-20190802002435809"></p>
<p><strong>出现这个之后一定要先做一件事情：点击下图标号1，开发者框中的「Network」按钮，然后再将页面进行刷新（按 F5，或者如图点击标号2的刷新图标）如下图：</strong></p>
<p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g5p995jo04j31bx0u0jvk.jpg" alt="image-20190802004144553"></p>
<p>想要找到评论我们需要全文搜索<strong>评论元素</strong>，当然不要忘记了，用过 Word我们肯定知道，Control键+F 是可以全文进行搜索的，在这里当然也管用。</p>
<p>我们试一下：先复制第一条评论<em>“非常不错啊！有理论，更有实践，没节都有些tips可以使用。真好。强烈推荐。”</em></p>
<p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g5p98zr984j30ul0u0tbt.jpg" alt="image-20190802002742769"></p>
<p>然后点击一下开发者区域（也就是我们之前按 F12 之后出现的区域），按下 <strong>Control + F</strong>（Mac 下面是 Command +  F），会在左边出现一个搜索框：我们将复制的评论粘贴在搜索框中，并按下<strong>回车键</strong></p>
<p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g5p99ahotzj31bx0u07bu.jpg" alt="image-20190802004517867"></p>
<p><strong>我们点击搜索出现的第一条内容，如上图箭头所指示，会在右边出现下面的内容：</strong></p>
<p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g5p98z7gerj31bx0u07ap.jpg" alt="image-20190802004710937"></p>
<p>我们的目的是要找<strong>链接</strong>，观察到有一个<strong>headers</strong>，没错，链接就藏在里面，点击查看：</p>
<p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g5p98txpahj325g0sigvc.jpg" alt="image-20190802004935850"></p>
<p>我们稍微简单解释一下几条信息：</p>
<ul>
<li><p>Request URL：URL代表的是Uniform Resource Locator,统一资源定位符，它是WWW的统一资源定位标志，就是指网络地址。比如说“www.baidu.com”这就是一个 <strong>URL</strong>。</p>
<p>  那很显然了，这个<strong>URL</strong>请求的链接就是服务器返回给浏览器的评论的链接。</p>
</li>
<li><p>Request Method：GET，这个代表的是 Request 这个请求的方法。如果我们搜索 Request 这个关键词，就会发现 Request 其实是客户端用来发送请求的一个对象，而 Request 对象有好几种方法，GET 是其中一种，Request 利用这些方法向服务器发送请求。</p>
<p>  这个在这里不重要，简单了解即可。</p>
</li>
<li><p>Status Code：200。字面含义就很清楚了，状态编码，我们用200来代表，请求成功，当然，还有一些其他的编码，比如我们所熟悉的 404 网页不存在，或者不到网页（如果你没有碰到过404的话，没关系，你可以在浏览器中输入”www.google.com”，404就会出现的）</p>
</li>
</ul>
<h4 id="真正的开始"><a href="#真正的开始" class="headerlink" title="真正的开始"></a>真正的开始</h4><p>别忘了，我们的主要目的是干什么——找到评论链接，事实上我们已经找到了，就在上面的 Request URL中，我们不妨复制下来看看它有什么特征</p>
<p>“<a href="https://sclub.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98vv2788&amp;productId=11990777&amp;score=0&amp;sortType=5&amp;page=0&amp;pageSize=10&amp;isShadowSku=0&amp;fold=1”" target="_blank" rel="noopener">https://sclub.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98vv2788&amp;productId=11990777&amp;score=0&amp;sortType=5&amp;page=0&amp;pageSize=10&amp;isShadowSku=0&amp;fold=1”</a></p>
<p>嚯，这实在是太难了，如果我们之前从没有接触过的话，我们几乎不可能看出它有什么重要特征。</p>
<p>不要紧，事实上，这只是第一个评论页面的链接，我们不妨再找一下第二页评论的链接，然后我们来找区别，这样就会有一些特征出现。</p>
<p>第二页评论：我们先点击评论的数字 2</p>
<p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g5p98shx7oj319w0u0dkw.jpg" alt="image-20190802010558366"></p>
<p>然后按照上面所说的方法，复制当前页面的第一个评论，然后去开发者页面中的搜索框中搜索，然后点击出现的第一条内容，然后再在右边查看 <strong>headers</strong> 中的 <strong>Request URL</strong> 的内容，第二个链接：</p>
<p>”<a href="https://sclub.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98vv2788&amp;productId=11990777&amp;score=0&amp;sortType=5&amp;page=1&amp;pageSize=10&amp;isShadowSku=0&amp;rid=0&amp;fold=1“" target="_blank" rel="noopener">https://sclub.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98vv2788&amp;productId=11990777&amp;score=0&amp;sortType=5&amp;page=1&amp;pageSize=10&amp;isShadowSku=0&amp;rid=0&amp;fold=1“</a></p>
<p>好了，开始找不同，我们用文本对比网页（搜索引擎搜索“文本对比”即可出现相关链接）会很快发现，有一个明显的异同点：</p>
<p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g5p992mwjqj31ow0u0aev.jpg" alt="image-20190802011421852"></p>
<p>为什么是 0 和 1 呢？如果我们再看第三页会怎样呢？</p>
<p>事实上，当第三页，这个二者有不同的地方就变成了数字2，好了，这一切都联系起来了。从 0 开始代表了第一页，之后每增加一页，数字加1。</p>
<p>知道了上面这些，意味着我们可以真正开始大量爬取评论数据了。</p>
<h4 id="爬取第一页评论"><a href="#爬取第一页评论" class="headerlink" title="爬取第一页评论"></a>爬取第一页评论</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">comment_spider</span><span class="params">()</span>:</span></span><br><span class="line">  	url =<span class="string">"https://sclub.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98vv2783&amp;productId=11990777&amp;score=0&amp;sortType=5&amp;page=1&amp;pageSize=10&amp;isShadowSku=0&amp;rid=0&amp;fold=1"</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url)</span><br><span class="line">        print(r.status_code)</span><br><span class="line">        print(<span class="string">"评论数据："</span>+r.text[:<span class="number">100</span>])</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">"爬取失败"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    comment_spider()</span><br></pre></td></tr></table></figure>
<p>上面我们定义了一个函数<strong>comment_spider( ) </strong> ，这个函数里面的<strong>URL</strong>是我们上面费力找到的。</p>
<p>然后，我们通过使用try，尝试对<strong>URL</strong>进行数据爬取：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r = requests.get(url)</span><br></pre></td></tr></table></figure>
<p>这是我们利用<strong>Requests</strong>发起一个<strong>GET</strong>请求，并把请求到的数据赋值给r。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(r.status_code)</span><br></pre></td></tr></table></figure>
<p>我们利用<strong>r.status_code</strong>来查看，请求内容是否成功，我们在之前说过，如果返回200，代表请求成功，如果返回404，证明访问的内容不存在。当然，还有可能返回到其他的编码，但我们想要的显然是 200</p>
<p><strong>如果try</strong>语句之后的内容执行失败，我们就会执行<strong>except</strong>后面的内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    comment_spider()</span><br></pre></td></tr></table></figure>
<p>上面的代码，即为一个主函数执行函数入口，在主函数里我们执行编写的<strong>comment__spider()</strong> 函数</p>
<p><strong>执行一下看一下</strong></p>
<p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g5p993y9esj30u00za0vl.jpg" alt="s"></p>
<p>可以看到，返回 200 访问成功的状态编码，意味着我们的<strong>URL</strong>访问没有问题，但是为什么没有任何的评论数据显示呢？</p>
<p>事实上，这是我们请求的时候，服务器核验我们出了差错，这是基础的反爬虫措施，我们返回开发者页面，进行查看。</p>
<p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g5p9933zhgj31bx0u07b9.jpg" alt="image-20190802183708060"></p>
<p>有一个<strong>Requests Headers</strong>，这是一个请求头，我们需要在利用<strong>requests.get</strong>方法发起请求的时候，把这个请求头加上，这样服务器就能够正常返回我们想要的内容。</p>
<p>我们需要设置一个字典：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kv = &#123;<span class="string">'user-agent'</span>: <span class="string">'Mozilla/5.0'</span>,<span class="string">'Referer'</span>:<span class="string">'https://item.jd.com/11990777.html'</span>&#125;</span><br></pre></td></tr></table></figure>
<p>这里面包含的<strong>user-agent</strong>代表发起请求的浏览器信息，<strong>Refeer</strong>用于标识请求的来源</p>
<p>然后我们修改<strong>requests.get</strong>请求，把我们的请求头加上：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r = requests.get(url,headers = kv)</span><br></pre></td></tr></table></figure>
<p>完整代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">comment_spider</span><span class="params">()</span>:</span></span><br><span class="line">    url = <span class="string">"https://sclub.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98vv2783&amp;productId=11990777&amp;score=0&amp;sortType=5&amp;page=0&amp;pageSize=10&amp;isShadowSku=0&amp;rid=0&amp;fold=1"</span></span><br><span class="line">    kv = &#123;<span class="string">'user-agent'</span>: <span class="string">'Mozilla/5.0'</span>,<span class="string">'Referer'</span>:<span class="string">'https://item.jd.com/11990777.html'</span>&#125;</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url,headers = kv)</span><br><span class="line">        print(r.status_code)</span><br><span class="line">        print(<span class="string">"评论数据："</span>+r.text[:<span class="number">100</span>])</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">"爬取失败"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    comment_spider()</span><br></pre></td></tr></table></figure>
<p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g5p991ztw8j30u00zaapz.jpg" alt="image-20190802185102214"></p>
<p>可以看到打印的内容，我们可以获取到想要的想要的评论数据。</p>
<h4 id="值得一提的小细节"><a href="#值得一提的小细节" class="headerlink" title="值得一提的小细节"></a>值得一提的小细节</h4><p>我们通过查看打印内容，真正的<strong>JSON</strong>数据是<strong>{ }</strong>里面的内容，也就是，去掉前面的<strong>“fetchJSON_comment98vv2783( “</strong> 和 后面的 <strong>“); “</strong> 的内容。</p>
<p>我们用<strong>切片</strong>的方法，来获取这段<strong>JSON</strong>数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r_json_str = r.text[<span class="number">26</span>:<span class="number">-2</span>]</span><br></pre></td></tr></table></figure>
<p>这段代码定义一个  <strong>r_json_str</strong> 的变量，其中<strong>[26:-2]</strong> 表示将r.text 内容的第26个到倒数第2个字符切下来。</p>
<h4 id="数据分析与提取"><a href="#数据分析与提取" class="headerlink" title="数据分析与提取"></a>数据分析与提取</h4><p>我们上面获得到的数据，其实是<strong>JSON</strong>数据，至于<strong>JSON</strong>是什么，我们现在只需要知道，它是一种数据交换格式，可以用来传递一些数据。</p>
<p>我们通过开发者模式中的<strong>Preview</strong>便可以稍微查看一下有什么数据，也可以百度搜索 <strong>JSON</strong>解析链接后，将 <strong>JSON</strong> 数据粘贴进去查看解析数据。</p>
<p>这里我们利用 <strong>Chrome</strong> 的 <strong>Preview</strong> 功能查看一下。</p>
<p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g5p997r6x0j31bx0u047m.jpg" alt="image-20190802185550522"></p>
<p>可以发现有一个<strong>comment</strong>，这个数据其实是一个字典格式。</p>
<p>python 有一个库，可以方便的查看字典格式，将整个层次分割开来。</p>
<p>我们先利用 <strong>import</strong> 导入这个库</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pprint</span><br></pre></td></tr></table></figure>
<p>然后下面的代码可以查看 <strong>JSON</strong> 解析数据字典格式的层次结构</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = json.loads(r.text[<span class="number">26</span>:<span class="number">-2</span>])</span><br><span class="line">pprint.pprint(data)</span><br></pre></td></tr></table></figure>
<p>完整代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> pprint</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">comment_spider</span><span class="params">()</span>:</span></span><br><span class="line">    url = <span class="string">"https://sclub.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98vv2783&amp;productId=11990777&amp;score=0&amp;sortType=5&amp;page=0&amp;pageSize=10&amp;isShadowSku=0&amp;rid=0&amp;fold=1"</span></span><br><span class="line">    kv = &#123;<span class="string">'user-agent'</span>: <span class="string">'Mozilla/5.0'</span>,<span class="string">'Referer'</span>:<span class="string">'https://item.jd.com/11990777.html'</span>&#125;</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url,headers = kv,timeout = <span class="number">100</span>)</span><br><span class="line">        data = json.loads(r.text[<span class="number">26</span>:<span class="number">-2</span>])</span><br><span class="line">        pprint.pprint(data)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">"爬取失败"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    comment_spider()</span><br></pre></td></tr></table></figure>
<p>打印出的字典结构：</p>
<p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g5p996ggu4j31d50u0tdg.jpg" alt="image-20190805222738285"></p>
<p>可以看到评论内容存在content对象中，所以我们只需要循环出所有 <strong>comments</strong> 中的 <strong>content</strong> 对象中内容，就能将所有的评论取出来。</p>
<p>然后我们尝试把评论打印出来</p>
<p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g5p990di8fj31c00u0gub.jpg" alt="image-20190805223742596"></p>
<p>完整代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> pprint</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">comment_spider</span><span class="params">()</span>:</span></span><br><span class="line">    url = <span class="string">"https://sclub.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98vv2783&amp;productId=11990777&amp;score=0&amp;sortType=5&amp;page=0&amp;pageSize=10&amp;isShadowSku=0&amp;rid=0&amp;fold=1"</span></span><br><span class="line">    kv = &#123;<span class="string">'user-agent'</span>: <span class="string">'Mozilla/5.0'</span>,<span class="string">'Referer'</span>:<span class="string">'https://item.jd.com/11990777.html'</span>&#125;</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url,headers = kv,timeout = <span class="number">100</span>)</span><br><span class="line">        <span class="comment">#获取到json的字符串</span></span><br><span class="line">        r_json_str = r.text[<span class="number">26</span>:<span class="number">-2</span>]</span><br><span class="line">        <span class="comment">#字符串转换为json对象</span></span><br><span class="line">        r_json_obj = json.loads(r_json_str)        </span><br><span class="line">        <span class="comment">#获取到json字典中的comments对象</span></span><br><span class="line">        r_json_comments = r_json_obj[<span class="string">'comments'</span>]</span><br><span class="line">        <span class="comment">#循环打印出所有的评论数据</span></span><br><span class="line">        <span class="keyword">for</span> comment <span class="keyword">in</span> r_json_comments:</span><br><span class="line">            print(comment[<span class="string">'content'</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">"爬取失败"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    comment_spider()</span><br></pre></td></tr></table></figure>
<h4 id="翻页处理，打印多页评论"><a href="#翻页处理，打印多页评论" class="headerlink" title="翻页处理，打印多页评论"></a>翻页处理，打印多页评论</h4><p>值得注意的是，我们上面只能打印出第一页的评论数据，这是因为我们的 <strong>URL</strong> 链接只是第一页的数据链接。</p>
<p>但我们前面已经分析过每个页码的 <strong>URL</strong> 差别其实就是 <strong>page=0</strong> 这个地方的不同，如下图：</p>
<p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g5koj6jwo6j31ow0u0grq.jpg" alt="image-20190802011421852"></p>
<p>所以我们只需要修改有差别的地方，便可以获取多页的数据。</p>
<p>怎样修改呢？</p>
<p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g5p994gjiwj31fu0qcq8v.jpg" alt="image-20190805230426523"></p>
<p>首先改造一下 <strong>comment_spider</strong> 函数，使其拥有一个默认参数 <strong>page = 0</strong>，也就是默认情况下爬取第1页内容，但为什么是数字0呢？这是因为编程习惯上使用0作为开始的下标。</p>
<p>上面这段代码，还包含一个 <strong>数据保存</strong> 的功能，其中的 <strong>FILE_PATH</strong> 就是文件路径，我们需要在开头的位置提前定义一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FILE_PATH = <span class="string">'book_comments.txt'</span></span><br></pre></td></tr></table></figure>
<p>然后，我们重复执行这个函数，每次将其参数 <strong>page</strong> 进行 <strong>+1</strong> 操作，就可以实现爬取多页数据，怎样实现这个重复呢？对，我们可以再定义一个函数来执行它啊！</p>
<p>我们定义 <strong>loop_spider()</strong> 函数来重复执行 <strong>comment_spider(page = 0)</strong> 这个函数，这样就达到目的了。</p>
<p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g5p9977n1tj30l60bijs3.jpg" alt="image-20190805231846821"></p>
<p>在这里我们首先用 <strong>python</strong> 的 <strong>OS</strong> 模块进行判断文件是否存在，如果存在先删除掉。然后再利用 <strong>for</strong> 循环执行 <strong>comment_spider(page = 0)</strong> 这个函数。在这里我们先执行10次。</p>
<p>还注意到，我们使用了 <strong>time</strong> 这个 <strong>python</strong> 库，这一行代码是用来进行延时处理的，这样做的目的是为了不让我们的爬虫操作太频繁，而被系统封掉 <strong>IP</strong></p>
<p>完整代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> pprint</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">FILE_PATH = <span class="string">'book_comments.txt'</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">comment_spider</span><span class="params">(page = <span class="number">0</span>)</span>:</span></span><br><span class="line">    url = <span class="string">'https://sclub.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98vv2783&amp;'</span> \</span><br><span class="line">    <span class="string">'productId=11990777&amp;score=0&amp;sortType=5&amp;page=%s&amp;pageSize=10&amp;isShadowSku=0&amp;rid=0&amp;fold=1'</span>%page</span><br><span class="line">    kv = &#123;<span class="string">'user-agent'</span>: <span class="string">'Mozilla/5.0'</span>,<span class="string">'Referer'</span>:<span class="string">'https://item.jd.com/11990777.html'</span>&#125;</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url,headers = kv,timeout = <span class="number">100</span>)</span><br><span class="line">        <span class="comment">#获取到json的字符串</span></span><br><span class="line">        r_json_str = r.text[<span class="number">26</span>:<span class="number">-2</span>]</span><br><span class="line">        <span class="comment">#字符串转换为json对象</span></span><br><span class="line">        r_json_obj = json.loads(r_json_str)        </span><br><span class="line">        <span class="comment">#获取到json字典中的comments对象</span></span><br><span class="line">        r_json_comments = r_json_obj[<span class="string">'comments'</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment">#循环打印出所有的评论数据, 并保存至指定文件</span></span><br><span class="line">        <span class="keyword">for</span> comment <span class="keyword">in</span> r_json_comments:</span><br><span class="line">            <span class="keyword">with</span> open(FILE_PATH,<span class="string">'a+'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(comment[<span class="string">'content'</span>]+<span class="string">'\n'</span>)</span><br><span class="line">            print(comment[<span class="string">'content'</span>])</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">"爬取失败"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loop_spider</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">        保存爬取数据</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="keyword">if</span> os._exists(<span class="string">"FILE_PATH"</span>):</span><br><span class="line">        os.remove(<span class="string">"FILE_PATH"</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">        comment_spider(i)</span><br><span class="line">        time.sleep(random.random() * <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment">#comment_spider()</span></span><br><span class="line">    loop_spider()</span><br></pre></td></tr></table></figure>
<p>这样一来，我们就能获取到很多评论数据，默认爬取10页评论，如果想要爬取更多，更改 <strong>loop_spider()</strong> 函数中的参数就能实现我们想要爬取的页数，比如改为50页：只需修改最后的主函数 <strong>loop_spider()</strong> 为 <strong>loop_spider(50)</strong></p>
<h4 id="生成云词"><a href="#生成云词" class="headerlink" title="生成云词"></a>生成云词</h4><p>生成云词我们定义两个函数，一个是用来获取，评论内容，并进行分词处理；另一个用来生成云词。</p>
<p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g5p998rmigj315g0u042r.jpg" alt="image-20190805232913819"></p>
<p>其中我们需要设置两个参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">WC_MASK_IMG = <span class="string">'ky.jpg'</span>  <span class="comment">#云词的背景图片</span></span><br><span class="line">WC_FONT_PATH = <span class="string">'/Library/Fonts/Songti.ttc'</span>	<span class="comment">#云词的默认字体</span></span><br></pre></td></tr></table></figure>
<p>最终的完整代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pprint</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kybook_path = <span class="string">'kybook.txt'</span></span><br><span class="line">WC_MASK_IMG = <span class="string">'ky.jpg'</span></span><br><span class="line">WC_FONT_PATH = <span class="string">'/Library/Fonts/Songti.ttc'</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">comment_spider</span><span class="params">(page = <span class="number">0</span>)</span>:</span></span><br><span class="line">    url = <span class="string">"https://sclub.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98vv2783&amp;productId=11990777&amp;score=0&amp;sortType=5&amp;page=%s&amp;pageSize=10&amp;isShadowSku=0&amp;rid=0&amp;fold=1"</span>%page</span><br><span class="line">    kv = &#123;<span class="string">'user-agent'</span>: <span class="string">'Mozilla/5.0'</span>,<span class="string">'Referer'</span>:<span class="string">'https://item.jd.com/11990777.html'</span>&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url,headers = kv)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">"spider failed."</span>)</span><br><span class="line">    r_json_str = r.text[<span class="number">26</span>:<span class="number">-2</span>]</span><br><span class="line">    r_json_obj = json.loads(r_json_str)</span><br><span class="line">    pprint.pprint(r_json_obj[<span class="string">'comments'</span>])</span><br><span class="line">    r_json_comments = r_json_obj[<span class="string">'comments'</span>]</span><br><span class="line">    <span class="keyword">for</span> r_json_comment <span class="keyword">in</span> r_json_comments:</span><br><span class="line">        <span class="keyword">with</span> open(kybook_path,<span class="string">'a+'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(r_json_comment[<span class="string">'content'</span>]+<span class="string">'\n'</span>)</span><br><span class="line">        print(r_json_comment[<span class="string">'content'</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bunch_comment_spider</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">if</span> os._exists(kybook_path):</span><br><span class="line">        os.remove(kybook_path)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">        comment_spider(i)</span><br><span class="line">        time.sleep(random.random() * <span class="number">5</span>)</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cut_word</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 打开爬取的评论数据文件</span></span><br><span class="line">    <span class="keyword">with</span> open(kybook_path) <span class="keyword">as</span> file:     </span><br><span class="line">        <span class="comment"># 读取文件内容</span></span><br><span class="line">        comment_txt = file.read()       </span><br><span class="line">        <span class="comment">#分词处理</span></span><br><span class="line">        wordlist = jieba.cut(comment_txt, cut_all=<span class="literal">True</span>)  </span><br><span class="line">        <span class="comment">#json处理   </span></span><br><span class="line">        wl = <span class="string">" "</span>.join(wordlist)                             </span><br><span class="line">        print(wl)</span><br><span class="line">        <span class="keyword">return</span> wl</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_word_cloud</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 设置词云形状图片</span></span><br><span class="line">    wc_mask = np.array(Image.open(WC_MASK_IMG))</span><br><span class="line">    <span class="comment"># 设置词云的一些配置，如：字体，背景色，词云形状，大小</span></span><br><span class="line">    wc = WordCloud(background_color=<span class="string">"white"</span>, max_words=<span class="number">2000</span>, mask=wc_mask, scale=<span class="number">4</span>,</span><br><span class="line">                   max_font_size=<span class="number">50</span>, random_state=<span class="number">42</span>, font_path=WC_FONT_PATH)</span><br><span class="line">    <span class="comment"># 生成词云</span></span><br><span class="line">    wc.generate(cut_word())</span><br><span class="line">    <span class="comment"># 在只设置mask的情况下,你将会得到一个拥有图片形状的词云</span></span><br><span class="line">    plt.imshow(wc, interpolation=<span class="string">"bilinear"</span>)</span><br><span class="line">    plt.axis(<span class="string">"off"</span>)</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment">#comment_spider()</span></span><br><span class="line">    <span class="comment">#bunch_comment_spider()</span></span><br><span class="line"></span><br><span class="line">    create_word_cloud()</span><br></pre></td></tr></table></figure>
<p>生成的效果：</p>
<p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g5p999mhymj30x90u0n4e.jpg" alt="image-20190805233245447"></p>
<p>我们就可以看到评论里最多的词语，进而可以有一个对这本书大致的分析判断。</p>

    </article>
    <!-- license  -->
    
    <!-- paginator  -->
    <ul class="post-paginator">
        <li class="next">
            
                <div class="nextSlogan">Next Post</div>
                <a href= "/2019/11/25/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%9B%BE%E7%9A%84%E6%A6%82%E5%BF%B5/" title= "数据结构-图的概念">
                    <div class="nextTitle">数据结构-图的概念</div>
                </a>
            
        </li>
        <li class="previous">
            
                <div class="prevSlogan">Previous Post</div>
                <a href= "/2019/07/17/%E7%89%A9%E8%81%94%E7%BD%91%E6%96%B0%E5%9E%8B%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E7%9A%84%E5%8F%91%E5%B1%95/" title= "物联网新型智慧城市的发展">
                    <div class="prevTitle">物联网新型智慧城市的发展</div>
                </a>
            
        </li>
    </ul>
    <!-- 评论插件 -->
    <!-- 来必力City版安装代码 -->

<!-- City版安装代码已完成 -->
    
    
    <!-- gitalk评论 -->

    <!-- utteranc评论 -->

    <!-- partial('_partial/comment/changyan') -->
    <!--PC版-->


    
    
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src='//unpkg.com/valine/dist/Valine.min.js'></script>
    <div id="comment"></div>
    <script>
    new Valine({
        el: '#comment' ,
        notify:false, 
        verify:false, 
        appId: "3z31za5tyuogWzU86rydsH0h-gzGzoHsz",
        appKey: "YeLtmtT5U8NP5GXTUesonkhB",
        placeholder: "",
        path:window.location.pathname, 
        avatar:'mm' 
    });
    </script>


    <!-- 评论 -->
</main>
            <!-- profile -->
            
        </div>
        <footer class="footer footer-unloaded">
    <!-- social  -->
    
    <div class="social">
        
    
        
            
                <a href="mailto:liylipsky@gmail.com" class="iconfont-archer email" title=email ></a>
            
        
    
        
            
                <a href="//github.com/bobouc" class="iconfont-archer github" target="_blank" title=github></a>
            
        
    
        
            
                <a href="/atom.xml" class="iconfont-archer rss" target="_blank" title=rss></a>
            
        
    

    </div>
    
    <!-- powered by Hexo  -->
    <div class="copyright">
        <span id="hexo-power">Powered by <a href="https://hexo.io/" target="_blank">Hexo</a></span><span class="iconfont-archer power">&#xe635;</span><span id="theme-info">theme <a href="https://github.com/fi3ework/hexo-theme-archer" target="_blank">Archer</a></span>
    </div>
    <!-- 不蒜子  -->
    
    <div class="busuanzi-container">
    
     
    <span id="busuanzi_container_site_pv">PV: <span id="busuanzi_value_site_pv"></span> :)</span>
    
    </div>
    
</footer>
    </div>
    <!-- toc -->
    
    <div class="toc-wrapper" style=
    







top:50vh;

    >
        <div class="toc-catalog">
            <span class="iconfont-archer catalog-icon">&#xe613;</span><span>CATALOG</span>
        </div>
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#爬取京东《刻意练习》图书评论并生成图词"><span class="toc-number">1.</span> <span class="toc-text">爬取京东《刻意练习》图书评论并生成图词</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#实现的目的"><span class="toc-number">1.0.0.1.</span> <span class="toc-text">实现的目的</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#上手"><span class="toc-number">1.0.0.2.</span> <span class="toc-text">上手</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#首先，我们需要打开京东关于这本书的评论，这很简单，用浏览器我们可以办得到（推荐使用-Chrome-浏览器，可能会更加方便）"><span class="toc-number">1.0.0.2.1.</span> <span class="toc-text">首先，我们需要打开京东关于这本书的评论，这很简单，用浏览器我们可以办得到（推荐使用 Chrome 浏览器，可能会更加方便）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#第一行代码"><span class="toc-number">1.0.0.3.</span> <span class="toc-text">第一行代码</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#导入-Requests-库"><span class="toc-number">1.0.0.3.1.</span> <span class="toc-text">导入 Requests 库</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#定义评论链接"><span class="toc-number">1.0.0.3.2.</span> <span class="toc-text">定义评论链接</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#找到评论链接"><span class="toc-number">1.0.0.4.</span> <span class="toc-text">找到评论链接</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#打开浏览器开发模式"><span class="toc-number">1.0.0.5.</span> <span class="toc-text">打开浏览器开发模式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#真正的开始"><span class="toc-number">1.0.0.6.</span> <span class="toc-text">真正的开始</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#爬取第一页评论"><span class="toc-number">1.0.0.7.</span> <span class="toc-text">爬取第一页评论</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#值得一提的小细节"><span class="toc-number">1.0.0.8.</span> <span class="toc-text">值得一提的小细节</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#数据分析与提取"><span class="toc-number">1.0.0.9.</span> <span class="toc-text">数据分析与提取</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#翻页处理，打印多页评论"><span class="toc-number">1.0.0.10.</span> <span class="toc-text">翻页处理，打印多页评论</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#生成云词"><span class="toc-number">1.0.0.11.</span> <span class="toc-text">生成云词</span></a></li></ol></li></ol></li></ol></li></ol>
    </div>
    
    <div class="back-top iconfont-archer">&#xe639;</div>
    <div class="sidebar sidebar-hide">
    <ul class="sidebar-tabs sidebar-tabs-active-0">
        <li class="sidebar-tab-archives"><span class="iconfont-archer">&#xe67d;</span><span class="tab-name">Archive</span></li>
        <li class="sidebar-tab-tags"><span class="iconfont-archer">&#xe61b;</span><span class="tab-name">Tag</span></li>
        <li class="sidebar-tab-categories"><span class="iconfont-archer">&#xe666;</span><span class="tab-name">Cate</span></li>
    </ul>
    <div class="sidebar-content sidebar-content-show-archive">
          <div class="sidebar-panel-archives">
    <!-- 在ejs中将archive按照时间排序 -->
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    <div class="total-and-search">
        <div class="total-archive">
        Total : 88
        </div>
        <!-- search  -->
        
    </div>
    
    <div class="post-archive">
    
    
    
    
    <div class="archive-year"> 2022 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/22</span><a class="archive-post-title" href= "/2022/04/22/Java-Reflect/" >Java Reflect</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/19</span><a class="archive-post-title" href= "/2022/04/19/Android%20Learning/" >Android Learning</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/04</span><a class="archive-post-title" href= "/2022/04/04/Thread-Process-and-Parallel-computing/" >Thread, Process and Parallel computing</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/02</span><a class="archive-post-title" href= "/2022/04/02/C-Smart-pointer/" >C++ Smart pointer</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/30</span><a class="archive-post-title" href= "/2022/03/30/Cmake-common-syntax/" >Cmake common syntax</a>
        </li>
    
    
    
    
    
        </ul>
    
    <div class="archive-year"> 2021 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/29</span><a class="archive-post-title" href= "/2021/11/29/LeetCode-TIPS/" >LeetCode TIPS</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/18</span><a class="archive-post-title" href= "/2021/08/18/golang-specific-notes/" >golang specific notes</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/07</span><a class="archive-post-title" href= "/2021/08/07/ListNode-Data-Structure/" >ListNode-Data Structure</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">07/13</span><a class="archive-post-title" href= "/2021/07/13/Slam-Learning/" >SLAM Learning</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/13</span><a class="archive-post-title" href= "/2021/06/13/A-Little-bit-of-Summary-Of-Deep-Learning/" >A Little bit of Summary Of Deep Learning</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">05/27</span><a class="archive-post-title" href= "/2021/05/27/git-frequently-used-actions/" >git frequently used actions</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">05/12</span><a class="archive-post-title" href= "/2021/05/12/OS-Learning-Linux-Homebrew/" >OS-Learning: Linux Homebrew</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">05/11</span><a class="archive-post-title" href= "/2021/05/11/Dynamic-Programming-Analysis/" >Dynamic Programming Analysis</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/24</span><a class="archive-post-title" href= "/2021/04/24/CUDA-coding/" >CUDA coding</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/23</span><a class="archive-post-title" href= "/2021/04/23/Sliding-Window/" >Sliding Window </a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/20</span><a class="archive-post-title" href= "/2021/04/20/Binary-Search/" >Binary Search</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/17</span><a class="archive-post-title" href= "/2021/04/17/logofapplegeniusbar/" >记一次苹果天才吧维修记录</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/01</span><a class="archive-post-title" href= "/2021/04/01/Learnopengl-note/" >Learnopengl-note</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/29</span><a class="archive-post-title" href= "/2021/03/29/Analysis-of-Dual-Attention-Network-for-Scene-Segmentation/" >Analysis of "Dual Attention Network for Scene Segmentation"</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/23</span><a class="archive-post-title" href= "/2021/03/23/Important-Conception-In-CG/" >Important Conception In CG</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/21</span><a class="archive-post-title" href= "/2021/03/21/Docker-notes/" >Docker notes</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/17</span><a class="archive-post-title" href= "/2021/03/17/Self-Learning-OF-Hongyi-Lee-Machine-Learning-Spring-Mandarin/" >Hongyi-Lee Machine Learning Spring 2021 Mandarin</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/22</span><a class="archive-post-title" href= "/2021/02/22/CPP-refresh/" >CPP refresh</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/03</span><a class="archive-post-title" href= "/2021/02/03/752-Open-the-Lock/" >752. Open the Lock</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/01</span><a class="archive-post-title" href= "/2021/02/01/Iteratively-144-Binary-Tree-Preorder-Inorder-Traversal/" >Iteratively. 144.Binary Tree Preorder&Inorder Traversal</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/29</span><a class="archive-post-title" href= "/2021/01/29/LeetCode-111-Minimum-Depth-of-Binary-Tree/" >LeetCode 111. Minimum Depth of Binary Tree</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/14</span><a class="archive-post-title" href= "/2021/01/14/full-permutation-with-backtracking/" >full permutation with backtracking</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/04</span><a class="archive-post-title" href= "/2021/01/04/Hyperspectral-Classification/" >高光谱分类-Hyperspectral Classification</a>
        </li>
    
    
    
    
    
        </ul>
    
    <div class="archive-year"> 2020 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/06</span><a class="archive-post-title" href= "/2020/12/06/LeetCode-322-Coin-Change/" >LeetCode 322. Coin Change</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/05</span><a class="archive-post-title" href= "/2020/12/05/LeetCode509-Fibonacci-Number/" >LeetCode509. Fibonacci Number</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/28</span><a class="archive-post-title" href= "/2020/11/28/Learn-AndrewNg-Ai-notes/" >Learn AndrewNg-MachineLearning notes</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/20</span><a class="archive-post-title" href= "/2020/11/20/LeetCode-Hanota-LCCI/" >LeetCode-Hanota LCCI</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/18</span><a class="archive-post-title" href= "/2020/11/18/DogsVSCats/" >DogsVSCats</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/14</span><a class="archive-post-title" href= "/2020/11/14/region-growsplitmerge-watershed/" >区域生长&区域分割与合成&分水岭算法</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/10</span><a class="archive-post-title" href= "/2020/11/10/threshouldeffecton2valueimg/" >不同阈值处理方法对于二值图像的影响</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/23</span><a class="archive-post-title" href= "/2020/10/23/%E9%A2%91%E7%8E%87%E5%9F%9F%E9%AB%98%E9%80%9A%E4%BD%8E%E9%80%9A%E6%BB%A4%E6%B3%A2-%E5%90%8C%E6%80%81%E6%BB%A4%E6%B3%A2/" >频率域高通低通滤波&同态滤波</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/19</span><a class="archive-post-title" href= "/2020/10/19/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86work-%E7%A9%BA%E9%97%B4%E5%9F%9F-%E5%9B%BE%E5%83%8F%E5%9F%9F-%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1%E5%8C%96-%E5%B9%B3%E6%BB%91%E7%A9%BA%E9%97%B4%E6%BB%A4%E6%B3%A2-%E9%94%90%E5%8C%96%E6%BB%A4%E6%B3%A2%E5%99%A8/" >数字图像处理work-空间域/图像域-直方图均衡化/平滑空间滤波/锐化滤波器</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/23</span><a class="archive-post-title" href= "/2020/09/23/std-vector-in-c/" >std::vector in c++</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/22</span><a class="archive-post-title" href= "/2020/09/22/Reverse-Integer/" >LeetCode 7.Reverse Integer</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/10</span><a class="archive-post-title" href= "/2020/03/10/LeetCode4-Median-of-Two-Sorted-Arrays/" >LeetCode4. Median of Two Sorted Arrays</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/07</span><a class="archive-post-title" href= "/2020/03/07/LeetCode628-Maximum-Product-of-Three-Numbers/" >LeetCode628. Maximum Product of Three Numbers</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/04</span><a class="archive-post-title" href= "/2020/03/04/LeetCode637-Average-of-Levels-in-Binary-Tree/" >LeetCode637. Average of Levels in Binary Tree</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/02</span><a class="archive-post-title" href= "/2020/03/02/LeetCode463-Island-Perimeter/" >LeetCode463. Island Perimeter</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/01</span><a class="archive-post-title" href= "/2020/03/01/%E6%9C%80%E5%B0%8F%E6%95%B0%E7%BB%84/" >最小数组</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/01</span><a class="archive-post-title" href= "/2020/03/01/%E6%AF%94%E8%BE%83%E5%A5%87%E5%81%B6%E4%B8%AA%E6%95%B0/" >比较奇偶个数</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/29</span><a class="archive-post-title" href= "/2020/02/29/LeetCode504-Base-7/" >LeetCode504. Base 7</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/27</span><a class="archive-post-title" href= "/2020/02/27/LeetCode551-Student-Attendance-Record-I/" >LeetCode551. Student Attendance Record I</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/26</span><a class="archive-post-title" href= "/2020/02/26/LeetCode-303-Range-Sum-Query-Immutable/" >LeetCode 303. Range Sum Query - Immutable</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/26</span><a class="archive-post-title" href= "/2020/02/26/LeetCode655-Print-Binary-Tree/" >LeetCode655. Print Binary Tree</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/24</span><a class="archive-post-title" href= "/2020/02/24/LeetCode561-Array-Partition-I/" >LeetCode561. Array Partition I </a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/23</span><a class="archive-post-title" href= "/2020/02/23/LeetCode566-Reshape-the-Matrix-%E9%87%8D%E7%BD%AE%E7%9F%A9%E9%98%B5/" >LeetCode566.Reshape the Matrix 重置矩阵</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/23</span><a class="archive-post-title" href= "/2020/02/23/LeetCode174-Dungeon-Game%F0%9F%A4%B4%E5%9C%B0%E7%8B%B1%E6%95%91%F0%9F%91%B8/" >LeetCode174. Dungeon Game🤴地狱救👸</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/20</span><a class="archive-post-title" href= "/2020/02/20/LeetCode-404-Sum-of-Left-Leaves-%E5%B7%A6%E5%8F%B6%E5%AD%90%E7%BB%93%E7%82%B9%E5%80%BC%E4%B9%8B%E5%92%8C/" >LeetCode 404. Sum of Left Leaves 左叶子结点值之和</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/19</span><a class="archive-post-title" href= "/2020/02/19/LeetCode-455-Assign-Cookies-%E9%A5%BC%E5%B9%B2%E5%88%86%E9%85%8D/" >LeetCode 455. Assign Cookies 饼干分配</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/18</span><a class="archive-post-title" href= "/2020/02/18/LeetCode-461-Hamming-Distance-%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB/" >LeetCode 461 Hamming Distance 汉明距离</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/16</span><a class="archive-post-title" href= "/2020/02/16/LeetCode-657-Judge-Route-Cricle-%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%98%AF%E5%90%A6%E8%BF%94%E5%9B%9E%E5%8E%9F%E7%82%B9/" >LeetCode 657 Judge Route Cricle 机器人是否返回原点</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/16</span><a class="archive-post-title" href= "/2020/02/16/LeetCode-1-Two-Sum/" >LeetCode 1 Two Sum</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/23</span><a class="archive-post-title" href= "/2020/01/23/Python-Error-Handing/" >Python_Error_Handing</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/12</span><a class="archive-post-title" href= "/2020/01/12/Python-Functional-Programming/" >Python_Functional_Programming</a>
        </li>
    
    
    
    
    
        </ul>
    
    <div class="archive-year"> 2019 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/25</span><a class="archive-post-title" href= "/2019/11/25/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%9B%BE%E7%9A%84%E6%A6%82%E5%BF%B5/" >数据结构-图的概念</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/06</span><a class="archive-post-title" href= "/2019/08/06/Spider-for-a-Book-Secrets-from-the-New-Science-of-Expertise-comments-on-JD-com/" >Spider for a Book "Secrets from the New Science of Expertise" comments on JD.com</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">07/17</span><a class="archive-post-title" href= "/2019/07/17/%E7%89%A9%E8%81%94%E7%BD%91%E6%96%B0%E5%9E%8B%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E7%9A%84%E5%8F%91%E5%B1%95/" >物联网新型智慧城市的发展</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">05/27</span><a class="archive-post-title" href= "/2019/05/27/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/" >树和二叉树</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/27</span><a class="archive-post-title" href= "/2019/03/27/PAT-1016-%E9%83%A8%E5%88%86A-B/" >PAT 1016 部分A+B</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/27</span><a class="archive-post-title" href= "/2019/03/27/C-C-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8-%E8%AF%AD%E6%B3%95%E9%80%9F%E9%80%92/" >C/C++快速入门-语法速递</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/24</span><a class="archive-post-title" href= "/2019/03/24/PAT-1014%E7%A6%8F%E5%B0%94%E6%91%A9%E6%96%AF%E7%9A%84%E7%BA%A6%E4%BC%9A/" >PAT 1014福尔摩斯的约会</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/21</span><a class="archive-post-title" href= "/2019/03/21/PAT-1013-%E6%95%B0%E7%B4%A0%E6%95%B0/" >PAT 1013 数素数</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/20</span><a class="archive-post-title" href= "/2019/03/20/Character-String-C/" >C语言字符串浅析 Character String (C)</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/19</span><a class="archive-post-title" href= "/2019/03/19/C-vector-%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/" >C++ vector 基础操作</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/19</span><a class="archive-post-title" href= "/2019/03/19/PAT-1012-%E6%95%B0%E5%AD%97%E5%88%86%E7%B1%BB/" >PAT 1012 数字分类</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/18</span><a class="archive-post-title" href= "/2019/03/18/PAT-1010-%E4%B8%80%E5%85%83%E5%A4%9A%E9%A1%B9%E5%BC%8F%E6%B1%82%E5%AF%BC/" >PAT 1010 一元多项式求导</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/18</span><a class="archive-post-title" href= "/2019/03/18/PAT-1011-A-B-%E5%92%8C-C/" >PAT 1011 A+B 和 C</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/13</span><a class="archive-post-title" href= "/2019/01/13/12306-Python-%E6%8A%A2%E8%BD%A6%E7%A5%A8%E5%BC%80%E6%BA%90%E7%A8%8B%E5%BA%8F%EF%BC%88%E7%AE%80%E6%98%93%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%EF%BC%89/" >12306 Python 抢车票开源程序（简易使用教程）</a>
        </li>
    
    
    
    
    
        </ul>
    
    <div class="archive-year"> 2018 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/31</span><a class="archive-post-title" href= "/2018/12/31/Android-learning-record/" >Android_learning_record</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/08</span><a class="archive-post-title" href= "/2018/12/08/%E5%8F%99%E8%BF%B0%E4%B8%80%E4%BA%9B%E7%AE%80%E7%BA%A6%E7%9A%84%E4%BA%8B/" >叙述一些简约的事</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/04</span><a class="archive-post-title" href= "/2018/12/04/Linux-learning-record/" >Linux_learning_record</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/29</span><a class="archive-post-title" href= "/2018/11/29/Data-Structure-C/" >Data Structure(C)</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/21</span><a class="archive-post-title" href= "/2018/11/21/Cortex-STM32F107-learning-record/" >Cortex-M3(STM32F107)_Learning_Notes</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/05</span><a class="archive-post-title" href= "/2018/10/05/The-method-of-get-in-Requests-lib/" >The method of get() in Requests lib</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/17</span><a class="archive-post-title" href= "/2018/09/17/Basic-Matrix-knowledge/" >Basic Matrix knowledge</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/14</span><a class="archive-post-title" href= "/2018/09/14/Numpy-generate-array/" >Numpy generate array</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/24</span><a class="archive-post-title" href= "/2018/08/24/Parse-web-pages-using-CSS-class-by-BeautifulSoup/" >Parse web pages using CSS class by BeautifulSoup</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/17</span><a class="archive-post-title" href= "/2018/08/17/Regular-Expression/" >Regular Expression</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/13</span><a class="archive-post-title" href= "/2018/08/13/Sets-Dictionaries/" >Sets & Dictionaries</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/11</span><a class="archive-post-title" href= "/2018/08/11/Character-string-and-Data-type/" >Character string and Data type</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/10</span><a class="archive-post-title" href= "/2018/08/10/Requests-details-of-Python/" >Requests' details of Python</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/20</span><a class="archive-post-title" href= "/2018/04/20/Virtual-Environment-For-Different-Projects/" >Virtual Environment For Different Projects</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/16</span><a class="archive-post-title" href= "/2018/04/16/20180416starspaceXtougao/" >我们一起数月亮，看星星。</a>
        </li>
    
    </div>
  </div>
        <div class="sidebar-panel-tags">
    <div class="sidebar-tags-name">
    
        <span class="sidebar-tag-name" data-tags="essay"><span class="iconfont-archer">&#xe606;</span>essay</span>
    
        <span class="sidebar-tag-name" data-tags="Deep Learning"><span class="iconfont-archer">&#xe606;</span>Deep Learning</span>
    
        <span class="sidebar-tag-name" data-tags="Paper-reading"><span class="iconfont-archer">&#xe606;</span>Paper-reading</span>
    
        <span class="sidebar-tag-name" data-tags="learning-note"><span class="iconfont-archer">&#xe606;</span>learning-note</span>
    
        <span class="sidebar-tag-name" data-tags="C++"><span class="iconfont-archer">&#xe606;</span>C++</span>
    
        <span class="sidebar-tag-name" data-tags="CUDA"><span class="iconfont-archer">&#xe606;</span>CUDA</span>
    
        <span class="sidebar-tag-name" data-tags="cmake"><span class="iconfont-archer">&#xe606;</span>cmake</span>
    
        <span class="sidebar-tag-name" data-tags="LeetCode"><span class="iconfont-archer">&#xe606;</span>LeetCode</span>
    
        <span class="sidebar-tag-name" data-tags="DataStructure"><span class="iconfont-archer">&#xe606;</span>DataStructure</span>
    
        <span class="sidebar-tag-name" data-tags="Numpy"><span class="iconfont-archer">&#xe606;</span>Numpy</span>
    
        <span class="sidebar-tag-name" data-tags="PAT"><span class="iconfont-archer">&#xe606;</span>PAT</span>
    
        <span class="sidebar-tag-name" data-tags="OS-Linux"><span class="iconfont-archer">&#xe606;</span>OS-Linux</span>
    
        <span class="sidebar-tag-name" data-tags="slidingwindow"><span class="iconfont-archer">&#xe606;</span>slidingwindow</span>
    
        <span class="sidebar-tag-name" data-tags="git"><span class="iconfont-archer">&#xe606;</span>git</span>
    
        <span class="sidebar-tag-name" data-tags="golang"><span class="iconfont-archer">&#xe606;</span>golang</span>
    
        <span class="sidebar-tag-name" data-tags="BuaaAssignments"><span class="iconfont-archer">&#xe606;</span>BuaaAssignments</span>
    
    </div>
    <div class="iconfont-archer sidebar-tags-empty">&#xe678;</div>
    <div class="tag-load-fail" style="display: none; color: #ccc; font-size: 0.6rem;">
    缺失模块。<br/>
    1、请确保node版本大于6.2<br/>
    2、在博客根目录（注意不是archer根目录）执行以下命令：<br/>
    <span style="color: #f75357; font-size: 1rem; line-height: 2rem;">npm i hexo-generator-json-content --save</span><br/>
    3、在根目录_config.yml里添加配置：
    <pre style="color: #787878; font-size: 0.6rem;">
jsonContent:
  meta: false
  pages: false
  posts:
    title: true
    date: true
    path: true
    text: false
    raw: false
    content: false
    slug: false
    updated: false
    comments: false
    link: false
    permalink: false
    excerpt: false
    categories: true
    tags: true</pre>
    </div> 
    <div class="sidebar-tags-list"></div>
</div>
        <div class="sidebar-panel-categories">
    <div class="sidebar-categories-name">
    
        <span class="sidebar-category-name" data-categories="Machine-Learning"><span class="iconfont-archer">&#xe60a;</span>Machine-Learning</span>
    
        <span class="sidebar-category-name" data-categories="Data-Structure"><span class="iconfont-archer">&#xe60a;</span>Data-Structure</span>
    
    </div>
    <div class="iconfont-archer sidebar-categories-empty">&#xe678;</div>
    <div class="sidebar-categories-list"></div>
</div>
    </div>
</div> 
    <script>
    var siteMeta = {
        root: "/",
        author: "jax"
    }
</script>
    <!-- CDN failover -->
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
    <script type="text/javascript">
        if (typeof window.$ === 'undefined')
        {
            console.warn('jquery load from jsdelivr failed, will load local script')
            document.write('<script src="/lib/jquery.min.js">\x3C/script>')
        }
    </script>
    <script src="/scripts/main.js"></script>
    <!-- algolia -->
    
    <!-- busuanzi  -->
    
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
    <!-- CNZZ  -->
    
    </div>
    <!-- async load share.js -->
    
        <script src="/scripts/share.js" async></script>    
     
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</body>
</html>


